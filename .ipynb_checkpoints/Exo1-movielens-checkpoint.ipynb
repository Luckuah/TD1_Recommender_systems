{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Implementing Matrix Factorization from Scratch\n",
    "\n",
    "**Course:** Recommender Systems <br>\n",
    "**Professor:** Guilherme MEDEIROS MACHADO <br>\n",
    "**Topic:** Collaborative Filtering with Matrix Factorization\n",
    "\n",
    "---\n",
    "\n",
    "## Goal of the Exercise\n",
    "\n",
    "The objective of this exercise is to build a movie recommender system by implementing the **Matrix Factorization** algorithm from scratch using Python. We will use the famous **MovieLens 100k** dataset. By the end of this notebook, you will have:\n",
    "\n",
    "1.  Understood the theoretical foundations of matrix factorization.\n",
    "2.  Implemented the algorithm using **Stochastic Gradient Descent (SGD)**.\n",
    "3.  Trained your model on real-world movie rating data.\n",
    "4.  Evaluated your model's performance using Root Mean Squared Error (RMSE).\n",
    "5.  Generated personalized top-10 movie recommendations for a specific user.\n",
    "\n",
    "This exercise forbids the use of pre-built matrix factorization libraries (like `surprise`, `lightfm`, etc.) to ensure you gain a deep understanding of the inner workings of the algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "## The Dataset: MovieLens 100k\n",
    "\n",
    "We will be using the MovieLens 100k dataset, a classic dataset in the recommender systems community. It contains:\n",
    "* 100,000 ratings (1-5) from...\n",
    "* 943 users on...\n",
    "* 1682 movies.\n",
    "\n",
    "You will need two files from this dataset:\n",
    "* `u.data`: The full dataset of 100k ratings. Each row is in the format: `user_id`, `item_id`, `rating`, `timestamp`.\n",
    "* `u.item`: Information about the movies (items). Each row contains the `item_id`, `movie_title`, and other metadata. We'll use it to get the movie names for our final recommendations.\n",
    "\n",
    "Let's start by downloading and exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>Heavyweights (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>Legends of the Fall (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>Jackie Brown (1997)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp                       title\n",
       "0      196      242       3  881250949                Kolya (1996)\n",
       "1      186      302       3  891717742    L.A. Confidential (1997)\n",
       "2       22      377       1  878887116         Heavyweights (1994)\n",
       "3      244       51       2  880606923  Legends of the Fall (1994)\n",
       "4      166      346       1  886397596         Jackie Brown (1997)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "# --- Download the dataset if it doesn't exist ---\n",
    "if not os.path.exists('ml-100k'):\n",
    "    print(\"Downloading MovieLens 100k dataset...\")\n",
    "    url = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "    urlretrieve(url, 'ml-100k.zip')\n",
    "    with zipfile.ZipFile('ml-100k.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    print(\"Download and extraction complete.\")\n",
    "\n",
    "# --- Load the data ---\n",
    "# u.data contains the ratings\n",
    "data_cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', names=data_cols)\n",
    "\n",
    "# u.item contains movie titles\n",
    "item_cols = ['item_id', 'title'] + [f'col{i}' for i in range(22)] # Remaining columns are not needed\n",
    "movies_df = pd.read_csv('ml-100k/u.item', sep='|', names=item_cols, encoding='latin-1', usecols=['item_id', 'title'])\n",
    "\n",
    "# Merge the two dataframes to have movie titles and ratings in one place\n",
    "df = pd.merge(ratings_df, movies_df, on='item_id')\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Data Preparation\n",
    "\n",
    "The raw data is a list of ratings. For matrix factorization, it's conceptually easier to think of our data as a large **user-item interaction matrix**, let's call it $R$. In this matrix:\n",
    "* The rows represent users.\n",
    "* The columns represent movies (items).\n",
    "* The value at cell $(u, i)$, denoted $R_{ui}$, is the rating user $u$ gave to movie $i$.\n",
    "\n",
    "This matrix is typically very **sparse**, as most users have only rated a small fraction of the available movies.\n",
    "\n",
    "Let's create this matrix using a Pandas pivot table. This will also help us determine the number of unique users and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df):\n",
    "    df_notes = df[df[\"rating\"].notnull()]\n",
    "    train, test = train_test_split(df_notes, test_size=0.2, random_state=42)\n",
    "    return (train, test)\n",
    "    \n",
    "def create_user_item_matrix(df):\n",
    "    \"\"\"\n",
    "    Creates the user-item interaction matrix from the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing user_id, item_id, and rating.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A user-item matrix with users as rows, items as columns, and ratings as values.\n",
    "                       NaNs indicate that a user has not rated an item.\n",
    "    \"\"\"\n",
    "    df=df[[\"user_id\",\"rating\",\"title\"]]\n",
    "    train,test=split_data(df)\n",
    "    R_train = train.pivot_table(index=\"user_id\", columns=\"title\", values=\"rating\")\n",
    "    R_test=test.pivot_table(index=\"user_id\", columns=\"title\", values=\"rating\")\n",
    "\n",
    "    all_titles = df[\"title\"].unique()\n",
    "\n",
    "    R_train = R_train.reindex(columns=all_titles)\n",
    "    R_test = R_test.reindex(columns=all_titles)\n",
    "    \n",
    "    return (R_train,R_test)\n",
    "    # TODO: Create a pivot table.\n",
    "    # The index should be 'user_id', columns 'item_id', and values 'rating'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R_train,R_test=create_user_item_matrix(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>Kolya (1996)</th>\n",
       "      <th>L.A. Confidential (1997)</th>\n",
       "      <th>Heavyweights (1994)</th>\n",
       "      <th>Legends of the Fall (1994)</th>\n",
       "      <th>Jackie Brown (1997)</th>\n",
       "      <th>Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)</th>\n",
       "      <th>Hunt for Red October, The (1990)</th>\n",
       "      <th>Jungle Book, The (1994)</th>\n",
       "      <th>Grease (1978)</th>\n",
       "      <th>Remains of the Day, The (1993)</th>\n",
       "      <th>...</th>\n",
       "      <th>Sleepover (1995)</th>\n",
       "      <th>Everest (1998)</th>\n",
       "      <th>Nobody Loves Me (Keiner liebt mich) (1994)</th>\n",
       "      <th>Getting Away With Murder (1996)</th>\n",
       "      <th>Scream of Stone (Schrei aus Stein) (1991)</th>\n",
       "      <th>Mamma Roma (1962)</th>\n",
       "      <th>Eighth Day, The (1996)</th>\n",
       "      <th>Girls Town (1996)</th>\n",
       "      <th>Silence of the Palace, The (Saimt el Qusur) (1994)</th>\n",
       "      <th>Dadetown (1995)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1664 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title    Kolya (1996)  L.A. Confidential (1997)  Heavyweights (1994)  \\\n",
       "user_id                                                                \n",
       "1                 5.0                       NaN                  NaN   \n",
       "2                 NaN                       NaN                  NaN   \n",
       "3                 NaN                       2.0                  NaN   \n",
       "4                 NaN                       NaN                  NaN   \n",
       "5                 NaN                       NaN                  NaN   \n",
       "6                 4.0                       4.0                  NaN   \n",
       "7                 NaN                       NaN                  NaN   \n",
       "8                 NaN                       NaN                  NaN   \n",
       "9                 4.0                       NaN                  NaN   \n",
       "10                NaN                       4.0                  NaN   \n",
       "\n",
       "title    Legends of the Fall (1994)  Jackie Brown (1997)  \\\n",
       "user_id                                                    \n",
       "1                               NaN                  NaN   \n",
       "2                               NaN                  NaN   \n",
       "3                               NaN                  5.0   \n",
       "4                               NaN                  NaN   \n",
       "5                               NaN                  NaN   \n",
       "6                               NaN                  NaN   \n",
       "7                               2.0                  NaN   \n",
       "8                               NaN                  NaN   \n",
       "9                               NaN                  NaN   \n",
       "10                              NaN                  NaN   \n",
       "\n",
       "title    Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)  \\\n",
       "user_id                                                                                \n",
       "1                                                      NaN                             \n",
       "2                                                      NaN                             \n",
       "3                                                      NaN                             \n",
       "4                                                      NaN                             \n",
       "5                                                      NaN                             \n",
       "6                                                      5.0                             \n",
       "7                                                      5.0                             \n",
       "8                                                      NaN                             \n",
       "9                                                      NaN                             \n",
       "10                                                     4.0                             \n",
       "\n",
       "title    Hunt for Red October, The (1990)  Jungle Book, The (1994)  \\\n",
       "user_id                                                              \n",
       "1                                     NaN                      NaN   \n",
       "2                                     NaN                      NaN   \n",
       "3                                     NaN                      NaN   \n",
       "4                                     NaN                      NaN   \n",
       "5                                     NaN                      NaN   \n",
       "6                                     NaN                      1.0   \n",
       "7                                     5.0                      4.0   \n",
       "8                                     NaN                      NaN   \n",
       "9                                     NaN                      NaN   \n",
       "10                                    NaN                      NaN   \n",
       "\n",
       "title    Grease (1978)  Remains of the Day, The (1993)  ...  Sleepover (1995)  \\\n",
       "user_id                                                 ...                     \n",
       "1                  NaN                             5.0  ...               NaN   \n",
       "2                  NaN                             NaN  ...               NaN   \n",
       "3                  NaN                             NaN  ...               NaN   \n",
       "4                  NaN                             NaN  ...               NaN   \n",
       "5                  1.0                             NaN  ...               NaN   \n",
       "6                  NaN                             3.0  ...               NaN   \n",
       "7                  5.0                             4.0  ...               NaN   \n",
       "8                  NaN                             NaN  ...               NaN   \n",
       "9                  NaN                             NaN  ...               NaN   \n",
       "10                 NaN                             NaN  ...               NaN   \n",
       "\n",
       "title    Everest (1998)  Nobody Loves Me (Keiner liebt mich) (1994)  \\\n",
       "user_id                                                               \n",
       "1                   NaN                                         NaN   \n",
       "2                   NaN                                         NaN   \n",
       "3                   NaN                                         NaN   \n",
       "4                   NaN                                         NaN   \n",
       "5                   NaN                                         NaN   \n",
       "6                   NaN                                         NaN   \n",
       "7                   NaN                                         NaN   \n",
       "8                   NaN                                         NaN   \n",
       "9                   NaN                                         NaN   \n",
       "10                  NaN                                         NaN   \n",
       "\n",
       "title    Getting Away With Murder (1996)  \\\n",
       "user_id                                    \n",
       "1                                    NaN   \n",
       "2                                    NaN   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "5                                    NaN   \n",
       "6                                    NaN   \n",
       "7                                    NaN   \n",
       "8                                    NaN   \n",
       "9                                    NaN   \n",
       "10                                   NaN   \n",
       "\n",
       "title    Scream of Stone (Schrei aus Stein) (1991)  Mamma Roma (1962)  \\\n",
       "user_id                                                                 \n",
       "1                                              NaN                NaN   \n",
       "2                                              NaN                NaN   \n",
       "3                                              NaN                NaN   \n",
       "4                                              NaN                NaN   \n",
       "5                                              NaN                NaN   \n",
       "6                                              NaN                NaN   \n",
       "7                                              NaN                NaN   \n",
       "8                                              NaN                NaN   \n",
       "9                                              NaN                NaN   \n",
       "10                                             NaN                NaN   \n",
       "\n",
       "title    Eighth Day, The (1996)  Girls Town (1996)  \\\n",
       "user_id                                              \n",
       "1                           NaN                NaN   \n",
       "2                           NaN                NaN   \n",
       "3                           NaN                NaN   \n",
       "4                           NaN                NaN   \n",
       "5                           NaN                NaN   \n",
       "6                           NaN                NaN   \n",
       "7                           NaN                NaN   \n",
       "8                           NaN                NaN   \n",
       "9                           NaN                NaN   \n",
       "10                          NaN                NaN   \n",
       "\n",
       "title    Silence of the Palace, The (Saimt el Qusur) (1994)  Dadetown (1995)  \n",
       "user_id                                                                       \n",
       "1                                                      NaN               NaN  \n",
       "2                                                      NaN               NaN  \n",
       "3                                                      NaN               NaN  \n",
       "4                                                      NaN               NaN  \n",
       "5                                                      NaN               NaN  \n",
       "6                                                      NaN               NaN  \n",
       "7                                                      NaN               NaN  \n",
       "8                                                      NaN               NaN  \n",
       "9                                                      NaN               NaN  \n",
       "10                                                     NaN               NaN  \n",
       "\n",
       "[10 rows x 1664 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: The Theory of Matrix Factorization\n",
    "\n",
    "The core idea is to **decompose** our large, sparse user-item matrix $R$ (size $m \\times n$) into two smaller, dense matrices:\n",
    "1.  A **user-feature matrix** $P$ (size $m \\times k$).\n",
    "2.  An **item-feature matrix** $Q$ (size $n \\times k$).\n",
    "\n",
    "Here, $k$ is the number of **latent factors**, which is a hyperparameter we choose. These latent factors represent hidden characteristics of users and items. For movies, a factor might represent the \"amount of comedy\" vs. \"drama\", or \"blockbuster\" vs. \"indie film\". For users, a factor might represent their preference for these characteristics.\n",
    "\n",
    "\n",
    "\n",
    "The prediction of a rating $\\hat{r}_{ui}$ that user $u$ would give to item $i$ is calculated by the dot product of the user's latent vector $p_u$ and the item's latent vector $q_i$:\n",
    "\n",
    "$$\\hat{r}_{ui} = p_u \\cdot q_i^T = \\sum_{k=1}^{K} p_{uk} q_{ik}$$\n",
    "\n",
    "Our goal is to find the matrices $P$ and $Q$ such that their product $P \\cdot Q^T$ is as close as possible to the known ratings in our original matrix $R$. We formalize this using a **loss function**. A common choice is the sum of squared errors, with **regularization** to prevent overfitting:\n",
    "\n",
    "$$L = \\sum_{(u,i) \\in \\mathcal{K}} (r_{ui} - \\hat{r}_{ui})^2 + \\lambda \\left( \\sum_{u} ||p_u||^2 + \\sum_{i} ||q_i||^2 \\right)$$\n",
    "\n",
    "Where:\n",
    "* $\\mathcal{K}$ is the set of $(u, i)$ pairs for which the rating $r_{ui}$ is known.\n",
    "* $\\lambda$ is the regularization parameter, another hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: The Algorithm - Stochastic Gradient Descent (SGD)\n",
    "\n",
    "To minimize our loss function $L$, we will use **Stochastic Gradient Descent (SGD)**. Instead of calculating the gradient over all known ratings (which is computationally expensive), SGD iterates through each known rating one by one and updates the parameters in the direction that minimizes the error for that single rating.\n",
    "\n",
    "For each known rating $r_{ui}$:\n",
    "1.  Calculate the prediction error: $e_{ui} = r_{ui} - \\hat{r}_{ui}$\n",
    "2.  Update the user and item latent vectors ($p_u$ and $q_i$) using the following update rules:\n",
    "\n",
    "$$p_u \\leftarrow p_u + \\alpha \\cdot (e_{ui} \\cdot q_i - \\lambda \\cdot p_u)$$\n",
    "$$q_i \\leftarrow q_i + \\alpha \\cdot (e_{ui} \\cdot p_u - \\lambda \\cdot q_i)$$\n",
    "\n",
    "Where:\n",
    "* $\\alpha$ is the **learning rate**, a hyperparameter that controls the step size.\n",
    "\n",
    "We repeat this process for a fixed number of **epochs** (iterations over the entire training dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Step-by-Step Implementation\n",
    "\n",
    "Let's build our model. First, we need to split our data into a training and a testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Initialization\n",
    "\n",
    "We need to initialize our user-feature matrix $P$ and item-feature matrix $Q$ with small random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_matrices(n_users, n_items, n_factors):\n",
    "    \"\"\"\n",
    "    Initializes the user-feature (P) and item-feature (Q) matrices.\n",
    "\n",
    "    Args:\n",
    "        n_users (int): Number of users.\n",
    "        n_items (int): Number of items.\n",
    "        n_factors (int): Number of latent factors.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - P (np.ndarray): The user-feature matrix (n_users x n_factors).\n",
    "            - Q (np.ndarray): The item-feature matrix (n_items x n_factors).\n",
    "    \"\"\"\n",
    "    # TODO: Initialize P and Q with small random values from a standard normal distribution.\n",
    "    P = np.random.normal(scale=0.1, size=(n_users, n_factors))\n",
    "    Q = np.random.normal(scale=0.1, size=(n_items, n_factors))\n",
    "    return (P,Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_items = R_train.shape\n",
    "n_factors=10\n",
    "P,Q= initialize_matrices(n_users, n_items, n_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 The Training Loop (SGD)\n",
    "\n",
    "This is the core of our algorithm. We will loop for a specified number of epochs. In each epoch, we will iterate over all known ratings in our training set `R_train` and update the corresponding user and item vectors in `P` and `Q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(R_train, P, Q, learning_rate, regularization, epochs):\n",
    "    R_train = R_train.to_numpy()\n",
    "    R_train = np.nan_to_num(R_train, nan=0.0)\n",
    "    r_predict = np.zeros(R_train.shape)\n",
    "    e = np.zeros(R_train.shape)\n",
    "    n_users, n_items = R_train.shape\n",
    "    for epoch in range(epochs):\n",
    "        L=0\n",
    "        for u in range(n_users):\n",
    "            for i in range(n_items):\n",
    "                if R_train[u][i] > 0:\n",
    "                    r_predict[u][i] = P[u].dot(Q[i])\n",
    "                    e[u][i]= R_train[u][i]-r_predict[u][i]\n",
    "                    p_u_old = P[u].copy()\n",
    "                    P[u]=P[u]+learning_rate*(e[u][i]*Q[i]-regularization*P[u])\n",
    "                    Q[i]=Q[i]+learning_rate*(e[u][i]*p_u_old-regularization*Q[i])\n",
    "                    L=L+(e[u][i]*e[u][i])+regularization*(np.sum(P[u]**2)+np.sum(Q[i]**2))\n",
    "        print (\"Epoch\",epoch,\"loss\",L)\n",
    "    \n",
    "                \n",
    "    return (P,Q)\n",
    "                \n",
    "                \n",
    "\n",
    "            \n",
    "        \n",
    "    \"\"\"\n",
    "    Trains the matrix factorization model using SGD.\n",
    "\n",
    "    Args:\n",
    "        R_train (np.ndarray): The training user-item matrix.\n",
    "        P (np.ndarray): The user-feature matrix.\n",
    "        Q (np.ndarray): The item-feature matrix.\n",
    "        learning_rate (float): The learning rate (alpha).\n",
    "        regularization (float): The regularization parameter (lambda).\n",
    "        epochs (int): The number of iterations over the training data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the trained P and Q matrices.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 52476.447794076244\n",
      "Epoch 1 loss 47967.17250196821\n",
      "Epoch 2 loss 43252.015811526784\n",
      "Epoch 3 loss 38603.44972172715\n",
      "Epoch 4 loss 34125.742609142464\n",
      "Epoch 5 loss 29948.673459851154\n",
      "Epoch 6 loss 26161.009953429395\n",
      "Epoch 7 loss 22800.786706234052\n",
      "Epoch 8 loss 19867.704620400065\n",
      "Epoch 9 loss 17337.518869102587\n",
      "Epoch 10 loss 15172.630685968705\n",
      "Epoch 11 loss 13329.613449995073\n",
      "Epoch 12 loss 11764.44776307062\n",
      "Epoch 13 loss 10435.78185088418\n",
      "Epoch 14 loss 9306.619970506928\n",
      "Epoch 15 loss 8344.91852647133\n",
      "Epoch 16 loss 7523.510830992956\n",
      "Epoch 17 loss 6819.672868137767\n",
      "Epoch 18 loss 6214.539788838527\n",
      "Epoch 19 loss 5692.500937225538\n",
      "Epoch 20 loss 5240.64135683899\n",
      "Epoch 21 loss 4848.258078671153\n",
      "Epoch 22 loss 4506.456299908562\n",
      "Epoch 23 loss 4207.819053301214\n",
      "Epoch 24 loss 3946.1396520001313\n",
      "Epoch 25 loss 3716.2056921378435\n",
      "Epoch 26 loss 3513.62456582005\n",
      "Epoch 27 loss 3334.682115636475\n",
      "Epoch 28 loss 3176.2277059976286\n",
      "Epoch 29 loss 3035.5803958000774\n",
      "Epoch 30 loss 2910.452033136918\n",
      "Epoch 31 loss 2798.8839831753216\n",
      "Epoch 32 loss 2699.1948903944867\n",
      "Epoch 33 loss 2609.9374104423837\n",
      "Epoch 34 loss 2529.86226182198\n",
      "Epoch 35 loss 2457.8882720801553\n",
      "Epoch 36 loss 2393.0773487318534\n",
      "Epoch 37 loss 2334.613507845879\n",
      "Epoch 38 loss 2281.7852550032117\n",
      "Epoch 39 loss 2233.97074316195\n",
      "Epoch 40 loss 2190.62523660478\n",
      "Epoch 41 loss 2151.2704947929005\n",
      "Epoch 42 loss 2115.4857586327225\n",
      "Epoch 43 loss 2082.900077533191\n",
      "Epoch 44 loss 2053.1857611771334\n",
      "Epoch 45 loss 2026.0527771418808\n",
      "Epoch 46 loss 2001.2439459634816\n",
      "Epoch 47 loss 1978.5308102184379\n",
      "Epoch 48 loss 1957.7100747312813\n",
      "Epoch 49 loss 1938.600531918986\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "regularization=0.001\n",
    "epochs=50\n",
    "P_train,Q_train=train_model(R_train, P, Q, learning_rate, regularization, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Evaluation\n",
    "\n",
    "After training, we must evaluate how well our model performs on unseen data. We will use the **Root Mean Squared Error (RMSE)**, which measures the average magnitude of the errors between predicted and actual ratings.\n",
    "\n",
    "The formula is:\n",
    "$$RMSE = \\sqrt{\\frac{1}{|\\mathcal{T}|} \\sum_{(u,i) \\in \\mathcal{T}} (r_{ui} - \\hat{r}_{ui})^2}$$\n",
    "\n",
    "Where $\\mathcal{T}$ is the set of ratings in our test set. A lower RMSE means better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(R_test, P, Q):\n",
    "    R_test = R_test.to_numpy()\n",
    "    R_test = np.nan_to_num(R_test, nan=0.0)\n",
    "    r_predict = np.zeros(R_test.shape)\n",
    "    error=0\n",
    "    T=0\n",
    "    n_users, n_items = R_test.shape\n",
    "    for u in range(n_users):\n",
    "        for i in range(n_items):\n",
    "            if R_test[u][i] > 0:\n",
    "                r_predict[u][i] = P[u].dot(Q[i])\n",
    "                error= error+ (R_test[u][i]-r_predict[u][i])**2\n",
    "                T=T+1\n",
    "    RMSE=np.sqrt(error/T)\n",
    "    return (RMSE)\n",
    "                \n",
    "    \"\"\"\n",
    "    Calculates the Root Mean Squared Error (RMSE) on the test set.\n",
    "\n",
    "    Args:\n",
    "        R_test (np.ndarray): The testing user-item matrix.\n",
    "        P (np.ndarray): The trained user-feature matrix.\n",
    "        Q (np.ndarray): The trained item-feature matrix.\n",
    "\n",
    "    Returns:\n",
    "        float: The RMSE value.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12984496318482\n"
     ]
    }
   ],
   "source": [
    "RMSE=calculate_rmse(R_test, P_train,Q_train)\n",
    "print (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Putting It All Together\n",
    "\n",
    "Now, let's connect all the pieces. We'll set our hyperparameters, initialize our matrices, train the model, and finally evaluate it.\n",
    "\n",
    "**Your Goal:** Tune the hyperparameters to achieve an **RMSE below 0.98**. A good model can even reach ~0.95. If your RMSE is higher, try adjusting the learning rate, regularization, number of factors, or epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 1120631.2228858448\n",
      "Epoch 1 loss 1111981.2100844672\n",
      "Epoch 2 loss 1099510.9929520423\n",
      "Epoch 3 loss 1076224.7401401675\n",
      "Epoch 4 loss 1027334.72756295\n",
      "Epoch 5 loss 929723.4143127124\n",
      "Epoch 6 loss 773523.028307528\n",
      "Epoch 7 loss 599363.5521224932\n",
      "Epoch 8 loss 465131.04741022893\n",
      "Epoch 9 loss 379244.68014423136\n",
      "Epoch 10 loss 323090.79707807803\n",
      "Epoch 11 loss 283840.906180726\n",
      "Epoch 12 loss 255243.46592432444\n",
      "Epoch 13 loss 233820.4669629916\n",
      "Epoch 14 loss 217396.90341373856\n",
      "Epoch 15 loss 204546.90944788745\n",
      "Epoch 16 loss 194309.70501232188\n",
      "Epoch 17 loss 186022.1430143001\n",
      "Epoch 18 loss 179216.1443617375\n",
      "Epoch 19 loss 173554.48979433498\n",
      "Epoch 20 loss 168789.7106423946\n",
      "Epoch 21 loss 164737.15895537607\n",
      "Epoch 22 loss 161256.9780226721\n",
      "Epoch 23 loss 158241.7879144207\n",
      "Epoch 24 loss 155608.119768328\n",
      "Epoch 25 loss 153290.35733515996\n",
      "Epoch 26 loss 151236.38542513465\n",
      "Epoch 27 loss 149404.41951456256\n",
      "Epoch 28 loss 147760.66523890782\n",
      "Epoch 29 loss 146277.56935012716\n",
      "Epoch 30 loss 144932.49790159936\n",
      "Epoch 31 loss 143706.72692391853\n",
      "Epoch 32 loss 142584.66435443438\n",
      "Epoch 33 loss 141553.24496479813\n",
      "Epoch 34 loss 140601.4560064191\n",
      "Epoch 35 loss 139719.96254105112\n",
      "Epoch 36 loss 138900.80943946927\n",
      "Epoch 37 loss 138137.18281014168\n",
      "Epoch 38 loss 137423.21783181053\n",
      "Epoch 39 loss 136753.84306460334\n",
      "Epoch 40 loss 136124.65361936766\n",
      "Epoch 41 loss 135531.8072923068\n",
      "Epoch 42 loss 134971.93907826583\n",
      "Epoch 43 loss 134442.0904700671\n",
      "Epoch 44 loss 133939.65071395435\n",
      "Epoch 45 loss 133462.30777947293\n",
      "Epoch 46 loss 133008.00725913147\n",
      "Epoch 47 loss 132574.91776989287\n",
      "Epoch 48 loss 132161.40170868672\n",
      "Epoch 49 loss 131765.99043516975\n",
      "Epoch 50 loss 131387.3631302692\n",
      "Epoch 51 loss 131024.32871859614\n",
      "Epoch 52 loss 130675.81035453541\n",
      "Epoch 53 loss 130340.83206158827\n",
      "Epoch 54 loss 130018.50718688375\n",
      "Epoch 55 loss 129708.02839138579\n",
      "Epoch 56 loss 129408.65894394781\n",
      "Epoch 57 loss 129119.72512623815\n",
      "Epoch 58 loss 128840.60958730818\n",
      "Epoch 59 loss 128570.74551269645\n",
      "Epoch 60 loss 128309.61149444261\n",
      "Epoch 61 loss 128056.72700618683\n",
      "Epoch 62 loss 127811.64840220583\n",
      "Epoch 63 loss 127573.96537151688\n",
      "Epoch 64 loss 127343.29778834923\n",
      "Epoch 65 loss 127119.29290890999\n",
      "Epoch 66 loss 126901.62287134075\n",
      "Epoch 67 loss 126689.98246206464\n",
      "Epoch 68 loss 126484.08711648252\n",
      "Epoch 69 loss 126283.67112656738\n",
      "Epoch 70 loss 126088.48603135101\n",
      "Epoch 71 loss 125898.29916947287\n",
      "Epoch 72 loss 125712.89237564923\n",
      "Epoch 73 loss 125532.06080510316\n",
      "Epoch 74 loss 125355.61187204429\n",
      "Epoch 75 loss 125183.36428983073\n",
      "Epoch 76 loss 125015.14720207844\n",
      "Epoch 77 loss 124850.79939505954\n",
      "Epoch 78 loss 124690.16858293593\n",
      "Epoch 79 loss 124533.11075831475\n",
      "Epoch 80 loss 124379.48960140755\n",
      "Epoch 81 loss 124229.17594185042\n",
      "Epoch 82 loss 124082.0472678618\n",
      "Epoch 83 loss 123937.9872780108\n",
      "Epoch 84 loss 123796.88547129593\n",
      "Epoch 85 loss 123658.63677187968\n",
      "Epoch 86 loss 123523.14118488008\n",
      "Epoch 87 loss 123390.30348037662\n",
      "Epoch 88 loss 123260.0329027945\n",
      "Epoch 89 loss 123132.24290321814\n",
      "Epoch 90 loss 123006.85089250607\n",
      "Epoch 91 loss 122883.77801319947\n",
      "Epoch 92 loss 122762.948928452\n",
      "Epoch 93 loss 122644.29162642888\n",
      "Epoch 94 loss 122527.7372387341\n",
      "Epoch 95 loss 122413.21987159703\n",
      "Epoch 96 loss 122300.67644866797\n",
      "Epoch 97 loss 122190.0465644092\n",
      "Epoch 98 loss 122081.27234713681\n",
      "Epoch 99 loss 121974.29833090652\n",
      "1.12984496318482\n"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameters ---\n",
    "# Number of latent factors (k)\n",
    "# Learning rate (alpha)\n",
    "# Regularization parameter (lambda)\n",
    "# Number of epochs\n",
    "k=150\n",
    "learning_rate=0.001\n",
    "regularization=0.1\n",
    "epochs=100\n",
    "\n",
    "\n",
    "# --- Initialization ---\n",
    "# Remember user and item IDs are 1-based, but our numpy arrays are 0-based.\n",
    "# The number of users/items from the shape of R_df is correct for 0-based indexing.\n",
    "\n",
    "R_train,R_test=create_user_item_matrix(df)\n",
    "P,Q= initialize_matrices(n_users, n_items, k)\n",
    "\n",
    "\n",
    "# --- Training ---\n",
    "P_train,Q_train=train_model(R_train, P, Q, learning_rate, regularization, epochs)\n",
    "\n",
    "\n",
    "# --- Evaluation ---\n",
    "RMSE=calculate_rmse(R_test, P_train,Q_train)\n",
    "print(RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Making Recommendations\n",
    "\n",
    "The ultimate goal is to recommend movies! Now that we have our trained matrices $P$ and $Q$, we can predict the rating for *any* user-item pair, including those the user has not seen yet.\n",
    "\n",
    "The process for a given user `user_id`:\n",
    "1.  Get the user's latent vector $p_u$ from the trained matrix $P$.\n",
    "2.  Calculate the predicted ratings for all items by taking the dot product of $p_u$ and the entire item-feature matrix $Q^T$.\n",
    "3.  Create a list of movie titles and their predicted ratings.\n",
    "4.  Filter out movies the user has already seen.\n",
    "5.  Sort the remaining movies by their predicted rating in descending order.\n",
    "6.  Return the top N movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_movies(user_id, P, Q, movie_titles_df, R_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Recommends top N movies for a given user.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): The ID of the user.\n",
    "        P (np.ndarray): The trained user-feature matrix.\n",
    "        Q (np.ndarray): The trained item-feature matrix.\n",
    "        movie_titles_df (pd.DataFrame): Dataframe with item_id and title.\n",
    "        R_df (pd.DataFrame): The original user-item matrix dataframe (for checking seen movies).\n",
    "        top_n (int): The number of movies to recommend.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe with the top N recommended movie titles and their predicted ratings.\n",
    "    \"\"\"\n",
    "    movie_titles = movie_titles_df['title'].values\n",
    "    R = R_df.values\n",
    "\n",
    "    num_items = R.shape[1]\n",
    "    r_predict = np.full(num_items, -np.inf) \n",
    "\n",
    "    for i in range(num_items):\n",
    "        if np.isnan(R[user_id, i]):\n",
    "            r_predict[i] = P[user_id].dot(Q[i])\n",
    "\n",
    "    top_indices = np.argsort(r_predict)[::-1][:top_n]\n",
    "\n",
    "    recommendations = np.vstack((movie_titles[top_indices],  np.round(r_predict[top_indices], 2))).T\n",
    "\n",
    "    return recommendations\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_R_df(df):\n",
    "    df=df[[\"user_id\",\"rating\",\"title\"]]\n",
    "    R_df = df.pivot_table(index=\"user_id\", columns=\"title\", values=\"rating\")\n",
    "    \n",
    "    return (R_df)\n",
    "\n",
    "R_df=create_R_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations= recommend_top_movies(1, P_train, Q_train, df, R_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Thinner (1996)' 4.64]\n",
      " ['Jumanji (1995)' 4.59]\n",
      " ['Home Alone (1990)' 4.56]\n",
      " ['When Harry Met Sally... (1989)' 4.54]\n",
      " ['Mimic (1997)' 4.5]\n",
      " ['Pulp Fiction (1994)' 4.49]\n",
      " ['Kiss the Girls (1997)' 4.49]\n",
      " [\"Devil's Own, The (1997)\" 4.49]\n",
      " ['Pulp Fiction (1994)' 4.47]\n",
      " ['River Wild, The (1994)' 4.47]]\n"
     ]
    }
   ],
   "source": [
    "print (recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
